
### WANDB METADATA

# this will be used to associate this run with a wandb project
WANDB_PROJECT         : "inat"
WANDB_LOG_FREQ        : 100
MULTIGPU              : true
VALIDATION_PASS_SIZE  : 150

#### EXPERIMENT PARAMETERS
TENSORBOARD_LOG_DIR   : "/root/inatVisionTraining/log_dir"
CHECKPOINT_DIR        : "/root/inatVisionTraining/checkpoints/ckpt"
FINAL_SAVE_DIR        : "/root/inatVisionTraining/final_model/final"
BACKUP_DIR            : "/root/inatVisionTraining/backup"
SHUFFLE_BUFFER_SIZE   : 10000


#### DATASET PARAMETERS

PRETRAINED_MODEL      : "imagenet"
TRAINING_DATA         : "/root/inatVisionTraining/training_set.csv"
VAL_DATA              : "/root/inatVisionTraining/validation_set.csv"
TEST_DATA             : "/root/inatVisionTraining/validation_set.csv"
NUM_CLASSES           : 9598
TRAIN_FULL_MODEL      : false
DO_LABEL_SMOOTH       : true
LABEL_SMOOTH_MODE     : "flat"
LABEL_SMOOTH_PCT   : 0.1


#### TRAINING PARAMETERS

# training policy - only use mixed precision=true if you
# have a recent NVIDIA GPU that supports CUDA 7.0 or later
TRAIN_MIXED_PRECISION : True

# size of batch, per gpu
BATCH_SIZE            : 32

# number of training epochs
NUM_EPOCHS            : 10

# initial learning rate for the model
INITIAL_LEARNING_RATE : 0.01
LR_DECAY_FACTOR       : 0.94
EPOCHS_PER_LR_DECAY   : 4


#### MODEL PARAMETERS

# neural network architecture
MODEL_NAME            : "efficientNetB1"

# size of input
IMAGE_SIZE            : [299,299]

# dropout percentage for layer between pool & logits
DROPOUT_PCT           : 0.5

# optiimzer
OPTIMIZER_NAME        : "rmsprop"
RMSPROP_RHO           : 0.9
RMSPROP_MOMENTUM      : 0.9
RMSPROP_EPSILON       : 1.0
LABEL_COLUMN_NAME     : "taxon_id"
